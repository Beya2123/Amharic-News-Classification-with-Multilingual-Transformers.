# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l5DhjY43Oj0NTnIisDRUuxivqX1ksG6a
"""

"""
Utility functions for Amharic News Classification with Transformers
Contains preprocessing, evaluation, visualization, and helper functions
"""

import re
import string
import numpy as np
import pandas as pd
import torch
import json
import pickle
import os
import warnings
from typing import List, Dict, Tuple, Optional, Union, Any
from pathlib import Path
from collections import Counter, defaultdict
from datetime import datetime

# Suppress warnings
warnings.filterwarnings('ignore')

# Text preprocessing utilities
class AmharicTextPreprocessor:
    """
    Class for preprocessing Amharic text data
    """

    # Amharic character ranges (Unicode)
    AMHARIC_RANGE = r'[\u1200-\u137F]'
    # Amharic punctuation and symbols
    AMHARIC_PUNCTUATION = r'[\u1360-\u1368]'
    # Amharic numbers
    AMHARIC_NUMBERS = r'[\u1369-\u137C]'

    @staticmethod
    def clean_text(text: str,
                   remove_numbers: bool = False,
                   remove_punctuation: bool = True,
                   keep_amharic_only: bool = False) -> str:
        """
        Clean Amharic text by removing unwanted characters

        Args:
            text: Input text
            remove_numbers: Whether to remove numbers
            remove_punctuation: Whether to remove punctuation
            keep_amharic_only: Keep only Amharic characters

        Returns:
            Cleaned text
        """
        if pd.isna(text):
            return ""

        text = str(text).strip()

        # Normalize whitespace
        text = re.sub(r'\s+', ' ', text)

        if keep_amharic_only:
            # Keep only Amharic characters and basic punctuation
            pattern = f'{AmharicTextPreprocessor.AMHARIC_RANGE}|{AmharicTextPreprocessor.AMHARIC_PUNCTUATION}|{AmharicTextPreprocessor.AMHARIC_NUMBERS}|\s'
            text = ''.join(re.findall(pattern, text))
        else:
            # Remove special characters but keep Amharic, Latin, numbers, and basic punctuation
            if remove_punctuation:
                # Keep only alphanumeric, Amharic characters, and spaces
                text = re.sub(r'[^\w\s\u1200-\u137F]', ' ', text)

            if remove_numbers:
                # Remove digits
                text = re.sub(r'\d+', '', text)

        # Remove extra whitespace again
        text = re.sub(r'\s+', ' ', text).strip()

        return text

    @staticmethod
    def normalize_amharic(text: str) -> str:
        """
        Normalize Amharic text (optional normalization rules)

        Args:
            text: Input Amharic text

        Returns:
            Normalized text
        """
        # Add any Amharic-specific normalization rules here
        # Example: Normalize similar characters, remove diacritics, etc.

        # Remove repetitive characters (more than 2 consecutive same characters)
        text = re.sub(r'(.)\1{2,}', r'\1\1', text)

        return text

    @staticmethod
    def tokenize_amharic(text: str, method: str = 'word') -> List[str]:
        """
        Tokenize Amharic text

        Args:
            text: Input text
            method: Tokenization method ('word' or 'character')

        Returns:
            List of tokens
        """
        text = AmharicTextPreprocessor.clean_text(text)

        if method == 'character':
            # Character tokenization
            return list(text)
        else:
            # Word tokenization (split by whitespace)
            return text.split()

    @staticmethod
    def get_text_statistics(texts: List[str]) -> Dict[str, Any]:
        """
        Get statistics about text data

        Args:
            texts: List of text documents

        Returns:
            Dictionary with statistics
        """
        if not texts:
            return {}

        # Calculate basic statistics
        lengths = [len(str(t).split()) for t in texts]
        char_lengths = [len(str(t)) for t in texts]

        # Count Amharic characters
        amharic_chars = sum(len(re.findall(AmharicTextPreprocessor.AMHARIC_RANGE, str(t))) for t in texts)
        total_chars = sum(char_lengths)

        stats = {
            'num_documents': len(texts),
            'avg_word_length': np.mean(lengths),
            'std_word_length': np.std(lengths),
            'min_word_length': np.min(lengths),
            'max_word_length': np.max(lengths),
            'avg_char_length': np.mean(char_lengths),
            'std_char_length': np.std(char_lengths),
            'total_amharic_chars': amharic_chars,
            'amharic_char_ratio': amharic_chars / total_chars if total_chars > 0 else 0,
            'vocabulary_size': len(set(' '.join(texts).split())),
            'most_common_words': Counter(' '.join(texts).split()).most_common(20)
        }

        return stats

# Data loading and preparation utilities
class DataProcessor:
    """
    Class for processing and preparing datasets
    """

    @staticmethod
    def load_dataset(file_path: str,
                     text_column: Optional[str] = None,
                     label_column: Optional[str] = None) -> pd.DataFrame:
        """
        Load dataset from CSV file

        Args:
            file_path: Path to CSV file
            text_column: Name of text column (auto-detect if None)
            label_column: Name of label column (auto-detect if None)

        Returns:
            DataFrame with dataset
        """
        try:
            df = pd.read_csv(file_path)
            print(f"Dataset loaded successfully. Shape: {df.shape}")

            # Auto-detect columns if not specified
            if text_column is None:
                text_column = DataProcessor._detect_text_column(df)

            if label_column is None:
                label_column = DataProcessor._detect_label_column(df)

            print(f"Text column: '{text_column}'")
            print(f"Label column: '{label_column}'")

            # Check for missing values
            missing_text = df[text_column].isnull().sum()
            missing_labels = df[label_column].isnull().sum()

            if missing_text > 0 or missing_labels > 0:
                print(f"Missing values: Text={missing_text}, Labels={missing_labels}")
                df = df.dropna(subset=[text_column, label_column])
                print(f"After removing missing values: {df.shape}")

            return df, text_column, label_column

        except Exception as e:
            print(f"Error loading dataset: {e}")
            raise

    @staticmethod
    def _detect_text_column(df: pd.DataFrame) -> str:
        """Detect text column automatically"""
        text_keywords = ['text', 'article', 'content', 'body', 'news', 'headline', 'title']

        for col in df.columns:
            col_lower = col.lower()
            for keyword in text_keywords:
                if keyword in col_lower:
                    return col

        # If not found, use first column that looks like text
        for col in df.columns:
            if df[col].dtype == 'object' and len(df[col].iloc[0]) > 20:
                return col

        return df.columns[0]

    @staticmethod
    def _detect_label_column(df: pd.DataFrame) -> str:
        """Detect label column automatically"""
        label_keywords = ['label', 'category', 'class', 'type', 'topic', 'target']

        for col in df.columns:
            col_lower = col.lower()
            for keyword in label_keywords:
                if keyword in col_lower:
                    return col

        # If not found, use second column or first non-text column
        if len(df.columns) > 1:
            return df.columns[1]

        return df.columns[0]

    @staticmethod
    def prepare_dataset(df: pd.DataFrame,
                        text_column: str,
                        label_column: str,
                        preprocess: bool = True) -> Tuple[np.ndarray, np.ndarray, Dict, Dict]:
        """
        Prepare dataset for training

        Args:
            df: Input DataFrame
            text_column: Name of text column
            label_column: Name of label column
            preprocess: Whether to preprocess text

        Returns:
            Tuple of (texts, labels, label2id, id2label)
        """
        # Extract texts
        texts = df[text_column].values

        if preprocess:
            print("Preprocessing texts...")
            preprocessor = AmharicTextPreprocessor()
            texts = np.array([preprocessor.clean_text(t) for t in texts])

        # Encode labels
        unique_labels = df[label_column].unique()
        label2id = {label: idx for idx, label in enumerate(sorted(unique_labels))}
        id2label = {idx: label for label, idx in label2id.items()}

        labels = np.array([label2id[label] for label in df[label_column]])

        print(f"Dataset prepared:")
        print(f"  Number of samples: {len(texts)}")
        print(f"  Number of classes: {len(label2id)}")
        print(f"  Classes: {list(label2id.keys())}")

        # Print class distribution
        class_dist = Counter(labels)
        print(f"  Class distribution:")
        for label_id, count in class_dist.items():
            label_name = id2label[label_id]
            print(f"    {label_name}: {count} samples ({count/len(labels)*100:.1f}%)")

        return texts, labels, label2id, id2label

    @staticmethod
    def create_data_splits(texts: np.ndarray,
                          labels: np.ndarray,
                          test_size: float = 0.2,
                          val_size: float = 0.1,
                          random_state: int = 42,
                          stratify: bool = True) -> Dict[str, Any]:
        """
        Create train, validation, and test splits

        Args:
            texts: Array of texts
            labels: Array of labels
            test_size: Proportion for test set
            val_size: Proportion for validation set (from training set)
            random_state: Random seed
            stratify: Whether to stratify splits based on labels

        Returns:
            Dictionary with splits
        """
        from sklearn.model_selection import train_test_split

        # First split: train+val and test
        stratify_param = labels if stratify else None
        train_val_texts, test_texts, train_val_labels, test_labels = train_test_split(
            texts, labels,
            test_size=test_size,
            random_state=random_state,
            stratify=stratify_param
        )

        # Second split: train and val
        if val_size > 0:
            # Adjust val_size relative to train+val set
            actual_val_size = val_size / (1 - test_size)
            stratify_param = train_val_labels if stratify else None

            train_texts, val_texts, train_labels, val_labels = train_test_split(
                train_val_texts, train_val_labels,
                test_size=actual_val_size,
                random_state=random_state,
                stratify=stratify_param
            )
        else:
            train_texts, train_labels = train_val_texts, train_val_labels
            val_texts, val_labels = np.array([]), np.array([])

        splits = {
            'train': {'texts': train_texts, 'labels': train_labels},
            'val': {'texts': val_texts, 'labels': val_labels},
            'test': {'texts': test_texts, 'labels': test_labels}
        }

        print(f"Data splits created:")
        print(f"  Train: {len(train_texts)} samples")
        if len(val_texts) > 0:
            print(f"  Validation: {len(val_texts)} samples")
        print(f"  Test: {len(test_texts)} samples")

        return splits

    @staticmethod
    def save_splits(splits: Dict[str, Any], save_dir: str):
        """
        Save data splits to disk

        Args:
            splits: Dictionary with data splits
            save_dir: Directory to save splits
        """
        os.makedirs(save_dir, exist_ok=True)

        for split_name, split_data in splits.items():
            if len(split_data['texts']) > 0:
                split_df = pd.DataFrame({
                    'text': split_data['texts'],
                    'label': split_data['labels']
                })
                split_df.to_csv(os.path.join(save_dir, f'{split_name}_split.csv'), index=False)

        print(f"Data splits saved to {save_dir}")

# Model evaluation utilities
class ModelEvaluator:
    """
    Class for model evaluation and metrics calculation
    """

    @staticmethod
    def calculate_metrics(y_true: np.ndarray,
                         y_pred: np.ndarray,
                         average: str = 'weighted') -> Dict[str, float]:
        """
        Calculate classification metrics

        Args:
            y_true: True labels
            y_pred: Predicted labels
            average: Averaging method for multiclass metrics

        Returns:
            Dictionary with metrics
        """
        from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                                   f1_score, confusion_matrix)

        metrics = {
            'accuracy': accuracy_score(y_true, y_pred),
            'precision': precision_score(y_true, y_pred, average=average),
            'recall': recall_score(y_true, y_pred, average=average),
            'f1_score': f1_score(y_true, y_pred, average=average)
        }

        # Per-class metrics for multiclass
        if len(np.unique(y_true)) > 2:
            precision_per_class = precision_score(y_true, y_pred, average=None)
            recall_per_class = recall_score(y_true, y_pred, average=None)
            f1_per_class = f1_score(y_true, y_pred, average=None)

            metrics['precision_per_class'] = precision_per_class
            metrics['recall_per_class'] = recall_per_class
            metrics['f1_per_class'] = f1_per_class

        # Confusion matrix
        metrics['confusion_matrix'] = confusion_matrix(y_true, y_pred)

        return metrics

    @staticmethod
    def print_classification_report(y_true: np.ndarray,
                                   y_pred: np.ndarray,
                                   id2label: Dict[int, str]):
        """
        Print detailed classification report

        Args:
            y_true: True labels
            y_pred: Predicted labels
            id2label: Mapping from label ID to label name
        """
        from sklearn.metrics import classification_report

        # Map label IDs to names if id2label is provided
        target_names = [id2label[i] for i in sorted(id2label.keys())]

        print("\n" + "="*60)
        print("Classification Report")
        print("="*60)
        print(classification_report(y_true, y_pred, target_names=target_names))

    @staticmethod
    def plot_confusion_matrix(y_true: np.ndarray,
                             y_pred: np.ndarray,
                             id2label: Dict[int, str],
                             save_path: Optional[str] = None):
        """
        Plot confusion matrix

        Args:
            y_true: True labels
            y_pred: Predicted labels
            id2label: Mapping from label ID to label name
            save_path: Path to save the plot
        """
        import matplotlib.pyplot as plt
        import seaborn as sns
        from sklearn.metrics import confusion_matrix

        # Calculate confusion matrix
        cm = confusion_matrix(y_true, y_pred)

        # Get label names
        labels = [id2label[i] for i in sorted(id2label.keys())]

        # Plot
        plt.figure(figsize=(10, 8))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=labels, yticklabels=labels)
        plt.title('Confusion Matrix')
        plt.ylabel('True Label')
        plt.xlabel('Predicted Label')
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Confusion matrix saved to {save_path}")

        plt.show()

    @staticmethod
    def plot_training_history(train_losses: List[float],
                             val_losses: List[float],
                             train_accs: List[float],
                             val_accs: List[float],
                             save_path: Optional[str] = None):
        """
        Plot training history

        Args:
            train_losses: Training losses per epoch
            val_losses: Validation losses per epoch
            train_accs: Training accuracies per epoch
            val_accs: Validation accuracies per epoch
            save_path: Path to save the plot
        """
        import matplotlib.pyplot as plt

        epochs = range(1, len(train_losses) + 1)

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

        # Plot losses
        ax1.plot(epochs, train_losses, 'b-', label='Training Loss')
        ax1.plot(epochs, val_losses, 'r-', label='Validation Loss')
        ax1.set_title('Training and Validation Loss')
        ax1.set_xlabel('Epochs')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)

        # Plot accuracies
        ax2.plot(epochs, train_accs, 'b-', label='Training Accuracy')
        ax2.plot(epochs, val_accs, 'r-', label='Validation Accuracy')
        ax2.set_title('Training and Validation Accuracy')
        ax2.set_xlabel('Epochs')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Training history plot saved to {save_path}")

        plt.show()

# Model saving and loading utilities
class ModelManager:
    """
    Class for managing model saving and loading
    """

    @staticmethod
    def save_model(model: torch.nn.Module,
                  tokenizer: Any,
                  label2id: Dict[str, int],
                  id2label: Dict[int, str],
                  save_dir: str,
                  model_name: str = "model"):
        """
        Save model and related artifacts

        Args:
            model: Trained model
            tokenizer: Tokenizer
            label2id: Label to ID mapping
            id2label: ID to label mapping
            save_dir: Directory to save model
            model_name: Name of the model
        """
        from transformers import AutoTokenizer, AutoModelForSequenceClassification

        # Create save directory
        model_dir = os.path.join(save_dir, model_name)
        os.makedirs(model_dir, exist_ok=True)

        # Save model
        model.save_pretrained(model_dir)

        # Save tokenizer
        tokenizer.save_pretrained(model_dir)

        # Save label mappings
        mappings = {
            'label2id': label2id,
            'id2label': id2label,
            'timestamp': datetime.now().isoformat(),
            'model_name': model_name
        }

        with open(os.path.join(model_dir, 'mappings.json'), 'w') as f:
            json.dump(mappings, f, indent=2)

        # Save model info
        model_info = {
            'num_labels': len(label2id),
            'model_type': model.__class__.__name__,
            'save_dir': model_dir,
            'save_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        with open(os.path.join(model_dir, 'model_info.json'), 'w') as f:
            json.dump(model_info, f, indent=2)

        print(f"Model saved to {model_dir}")
        return model_dir

    @staticmethod
    def load_model(model_dir: str,
                  device: torch.device = None):
        """
        Load saved model

        Args:
            model_dir: Directory containing saved model
            device: Device to load model on

        Returns:
            Tuple of (model, tokenizer, label2id, id2label)
        """
        from transformers import AutoTokenizer, AutoModelForSequenceClassification

        if device is None:
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        # Load model
        model = AutoModelForSequenceClassification.from_pretrained(model_dir)
        model.to(device)
        model.eval()

        # Load tokenizer
        tokenizer = AutoTokenizer.from_pretrained(model_dir)

        # Load label mappings
        mappings_path = os.path.join(model_dir, 'mappings.json')
        if os.path.exists(mappings_path):
            with open(mappings_path, 'r') as f:
                mappings = json.load(f)
            label2id = mappings['label2id']
            id2label = {int(k): v for k, v in mappings['id2label'].items()}
        else:
            # Try to get from model config
            label2id = model.config.label2id if hasattr(model.config, 'label2id') else {}
            id2label = model.config.id2label if hasattr(model.config, 'id2label') else {}

        print(f"Model loaded from {model_dir}")
        print(f"Number of labels: {len(label2id)}")

        return model, tokenizer, label2id, id2label

# Prediction utilities
class Predictor:
    """
    Class for making predictions with trained models
    """

    @staticmethod
    def predict_batch(texts: List[str],
                     model: torch.nn.Module,
                     tokenizer: Any,
                     id2label: Dict[int, str],
                     device: torch.device,
                     batch_size: int = 32,
                     max_length: int = 256) -> List[Dict[str, Any]]:
        """
        Predict labels for a batch of texts

        Args:
            texts: List of input texts
            model: Trained model
            tokenizer: Tokenizer
            id2label: ID to label mapping
            device: Device to run inference on
            batch_size: Batch size for inference
            max_length: Maximum sequence length

        Returns:
            List of prediction dictionaries
        """
        model.eval()
        predictions = []

        # Process in batches
        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i+batch_size]

            # Tokenize batch
            encodings = tokenizer(
                batch_texts,
                truncation=True,
                padding=True,
                max_length=max_length,
                return_tensors='pt'
            )

            # Move to device
            input_ids = encodings['input_ids'].to(device)
            attention_mask = encodings['attention_mask'].to(device)

            # Predict
            with torch.no_grad():
                outputs = model(input_ids=input_ids, attention_mask=attention_mask)
                logits = outputs.logits
                probabilities = torch.softmax(logits, dim=1)

                # Get predictions
                batch_preds = torch.argmax(logits, dim=1).cpu().numpy()
                batch_probs = probabilities.cpu().numpy()

                # Create prediction dictionaries
                for j, (pred_id, probs) in enumerate(zip(batch_preds, batch_probs)):
                    pred = {
                        'text': batch_texts[j],
                        'predicted_label': id2label[pred_id],
                        'predicted_label_id': int(pred_id),
                        'confidence': float(probs[pred_id]),
                        'probabilities': {id2label[k]: float(v) for k, v in enumerate(probs)}
                    }
                    predictions.append(pred)

        return predictions

    @staticmethod
    def predict_single(text: str,
                      model: torch.nn.Module,
                      tokenizer: Any,
                      id2label: Dict[int, str],
                      device: torch.device,
                      max_length: int = 256) -> Dict[str, Any]:
        """
        Predict label for a single text

        Args:
            text: Input text
            model: Trained model
            tokenizer: Tokenizer
            id2label: ID to label mapping
            device: Device to run inference on
            max_length: Maximum sequence length

        Returns:
            Prediction dictionary
        """
        return Predictor.predict_batch([text], model, tokenizer, id2label,
                                      device, batch_size=1, max_length=max_length)[0]

# Visualization utilities
class Visualizer:
    """
    Class for data and results visualization
    """

    @staticmethod
    def plot_class_distribution(labels: np.ndarray,
                               id2label: Dict[int, str],
                               title: str = "Class Distribution",
                               save_path: Optional[str] = None):
        """
        Plot class distribution

        Args:
            labels: Array of labels
            id2label: ID to label mapping
            title: Plot title
            save_path: Path to save the plot
        """
        import matplotlib.pyplot as plt
        import seaborn as sns

        # Count labels
        label_counts = Counter(labels)

        # Get label names and counts
        label_names = [id2label[label_id] for label_id in sorted(label_counts.keys())]
        counts = [label_counts[label_id] for label_id in sorted(label_counts.keys())]

        # Create plot
        plt.figure(figsize=(12, 6))
        bars = plt.bar(label_names, counts)

        # Add count labels on bars
        for bar, count in zip(bars, counts):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                    str(count), ha='center', va='bottom')

        plt.title(title)
        plt.xlabel('Class')
        plt.ylabel('Count')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')

        plt.show()

    @staticmethod
    def plot_text_length_distribution(texts: List[str],
                                     title: str = "Text Length Distribution",
                                     save_path: Optional[str] = None):
        """
        Plot distribution of text lengths

        Args:
            texts: List of texts
            title: Plot title
            save_path: Path to save the plot
        """
        import matplotlib.pyplot as plt

        # Calculate text lengths (in words)
        lengths = [len(str(text).split()) for text in texts]

        # Create plot
        plt.figure(figsize=(12, 6))
        plt.hist(lengths, bins=50, edgecolor='black', alpha=0.7)
        plt.title(title)
        plt.xlabel('Text Length (words)')
        plt.ylabel('Frequency')
        plt.grid(True, alpha=0.3)

        # Add statistics
        stats_text = f"Mean: {np.mean(lengths):.1f}\nStd: {np.std(lengths):.1f}\nMax: {np.max(lengths)}"
        plt.text(0.95, 0.95, stats_text,
                transform=plt.gca().transAxes,
                verticalalignment='top',
                horizontalalignment='right',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')

        plt.show()

# File utilities
class FileUtils:
    """
    Class for file operations
    """

    @staticmethod
    def create_directory_structure(base_dir: str = "./amharic_news_project"):
        """
        Create directory structure for the project

        Args:
            base_dir: Base directory for the project
        """
        directories = [
            base_dir,
            os.path.join(base_dir, 'data'),
            os.path.join(base_dir, 'data', 'raw'),
            os.path.join(base_dir, 'data', 'processed'),
            os.path.join(base_dir, 'data', 'splits'),
            os.path.join(base_dir, 'models'),
            os.path.join(base_dir, 'models', 'mbert'),
            os.path.join(base_dir, 'models', 'xlmr'),
            os.path.join(base_dir, 'models', 'afroxlmr'),
            os.path.join(base_dir, 'results'),
            os.path.join(base_dir, 'results', 'plots'),
            os.path.join(base_dir, 'results', 'reports'),
            os.path.join(base_dir, 'logs'),
            os.path.join(base_dir, 'configs')
        ]

        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            print(f"Created directory: {directory}")

        print(f"\nDirectory structure created at: {base_dir}")
        return base_dir

    @staticmethod
    def save_config(config: Dict[str, Any], config_path: str):
        """
        Save configuration to file

        Args:
            config: Configuration dictionary
            config_path: Path to save configuration
        """
        with open(config_path, 'w') as f:
            json.dump(config, f, indent=2)
        print(f"Configuration saved to {config_path}")

    @staticmethod
    def load_config(config_path: str) -> Dict[str, Any]:
        """
        Load configuration from file

        Args:
            config_path: Path to configuration file

        Returns:
            Configuration dictionary
        """
        with open(config_path, 'r') as f:
            config = json.load(f)
        print(f"Configuration loaded from {config_path}")
        return config

# Performance monitoring utilities
class PerformanceMonitor:
    """
    Class for monitoring model performance and resources
    """

    @staticmethod
    def get_gpu_info():
        """Get GPU information if available"""
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            gpu_info = []
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9  # GB
                gpu_info.append({
                    'id': i,
                    'name': gpu_name,
                    'memory_gb': gpu_memory
                })
            return gpu_info
        return None

    @staticmethod
    def monitor_memory():
        """Monitor GPU and CPU memory usage"""
        import psutil
        import humanize

        memory_info = {}

        # CPU memory
        cpu_memory = psutil.virtual_memory()
        memory_info['cpu'] = {
            'total': humanize.naturalsize(cpu_memory.total),
            'available': humanize.naturalsize(cpu_memory.available),
            'used': humanize.naturalsize(cpu_memory.used),
            'percent': cpu_memory.percent
        }

        # GPU memory (if available)
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated() / 1e9  # GB
            gpu_memory_max = torch.cuda.max_memory_allocated() / 1e9  # GB
            memory_info['gpu'] = {
                'allocated_gb': gpu_memory,
                'max_allocated_gb': gpu_memory_max,
                'cached_gb': torch.cuda.memory_cached() / 1e9
            }

        return memory_info

# Example usage functions
def example_usage():
    """
    Example usage of the utility functions
    """
    print("Example usage of utility functions:")
    print("="*60)

    # Initialize preprocessor
    preprocessor = AmharicTextPreprocessor()

    # Example text
    sample_text = "የኢትዮጵያ ብሔራዊ ቡድን ከኬንያ ጋር ይጫወታል። ይህ ጨዋታ በሰኔ ፲፩ ቀን ይካሄዳል።"

    # Clean text
    cleaned = preprocessor.clean_text(sample_text)
    print(f"Original: {sample_text}")
    print(f"Cleaned: {cleaned}")

    # Tokenize
    tokens = preprocessor.tokenize_amharic(cleaned)
    print(f"Tokens: {tokens}")

    # Get statistics
    stats = preprocessor.get_text_statistics([sample_text, cleaned])
    print(f"\nText statistics:")
    for key, value in stats.items():
        if key != 'most_common_words':
            print(f"  {key}: {value}")

if __name__ == "__main__":
    # Run example usage
    example_usage()