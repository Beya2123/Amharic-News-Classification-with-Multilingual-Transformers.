# -*- coding: utf-8 -*-
"""Transfer_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cWTnsW2FGBFbUwaPuhMh65uoQR1Bgrp5
"""

from google.colab import drive
drive.mount('/content/drive')

# Load data
CSV_PATH = "/content/drive/My Drive/Amharic News Dataset.csv"

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder
import torch
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    get_linear_schedule_with_warmup
)
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.auto import tqdm
import warnings
warnings.filterwarnings('ignore')

# Set up proper encoding for Amharic display
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'  # This supports Amharic characters
plt.rcParams['axes.unicode_minus'] = False

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class AmharicNewsDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=256):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]

        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

def load_and_prepare_data(csv_path):
    """Load and prepare the Amharic news dataset"""
    print("Loading dataset...")

    # Read the CSV file with proper encoding
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
    except:
        df = pd.read_csv(csv_path, encoding='latin-1')

    # Show available columns
    available_columns = df.columns.tolist()
    print(f"Available columns: {available_columns}")

    # Use the correct column names from your dataset
    text_column = 'article'  # This contains the news text
    label_column = 'category'  # This contains the category labels

    print(f"Using text column: '{text_column}'")
    print(f"Using label column: '{label_column}'")

    # Handle missing values and clean data
    df[text_column] = df[text_column].fillna('').astype(str)
    df[label_column] = df[label_column].fillna('Unknown')

    # Convert all labels to strings to handle mixed types
    df[label_column] = df[label_column].astype(str)

    # Remove any rows with empty text
    initial_count = len(df)
    df = df[df[text_column].str.strip() != '']
    df = df[df[text_column].str.len() > 10]  # Remove very short texts
    print(f"Removed {initial_count - len(df)} empty or very short texts")

    texts = df[text_column].values
    labels = df[label_column].values

    # Show some statistics about the data
    print(f"\nDataset statistics:")
    print(f"Total samples: {len(texts)}")

    # Calculate text length statistics safely
    text_lengths = [len(str(t)) for t in texts]
    print(f"Text length stats - Min: {min(text_lengths)}, "
          f"Max: {max(text_lengths)}, "
          f"Avg: {np.mean(text_lengths):.1f}")

    # Show unique categories
    unique_categories, category_counts = np.unique(labels, return_counts=True)
    print(f"\nUnique categories: {len(unique_categories)}")

    # Show all categories with their counts
    print("Category distribution:")
    category_info = []
    for category, count in zip(unique_categories, category_counts):
        percentage = count/len(labels)*100
        category_info.append((category, count, percentage))
        print(f"  '{category}': {count} samples ({percentage:.1f}%)")

    # Filter categories with too few samples (optional - for better accuracy)
    min_samples_per_class = 50  # Minimum samples per category
    category_counts_dict = dict(zip(unique_categories, category_counts))
    valid_categories = [cat for cat in unique_categories if category_counts_dict[cat] >= min_samples_per_class]

    if len(valid_categories) < len(unique_categories):
        print(f"\nFiltering categories with less than {min_samples_per_class} samples...")
        mask = np.isin(labels, valid_categories)
        texts = texts[mask]
        labels = labels[mask]
        print(f"After filtering: {len(texts)} samples, {len(valid_categories)} categories")

    # Convert labels to numerical values
    le = LabelEncoder()
    labels = le.fit_transform(labels)
    label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    num_classes = len(label_mapping)

    # Create reverse mapping for display
    label_mapping_inverse = {v: k for k, v in label_mapping.items()}

    print(f"\nNumber of classes: {num_classes}")
    print("Final label mapping:")
    for category, numeric_id in label_mapping.items():
        count = np.sum(labels == numeric_id)
        print(f"  '{category}' -> {numeric_id}: {count} samples")

    # Show sample data
    print("\nSample data:")
    for i in range(min(3, len(texts))):
        print(f"Sample {i+1}:")
        print(f"  Category: '{label_mapping_inverse.get(labels[i], labels[i])}' ({labels[i]})")
        print(f"  Text: {texts[i][:200]}...")
        print("-" * 80)

    return texts, labels, num_classes, label_mapping, label_mapping_inverse

def create_data_loaders(texts, labels, tokenizer, batch_size=16, max_length=256):
    """Create train, validation, and test data loaders"""
    # Split data: 70% train, 15% validation, 15% test
    X_temp, X_test, y_temp, y_test = train_test_split(
        texts, labels, test_size=0.15, random_state=42, stratify=labels
    )

    X_train, X_val, y_train, y_val = train_test_split(
        X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 * 0.85 = 0.15
    )

    print(f"Data split:")
    print(f"  Train size: {len(X_train)}")
    print(f"  Validation size: {len(X_val)}")
    print(f"  Test size: {len(X_test)}")

    # Create datasets
    train_dataset = AmharicNewsDataset(X_train, y_train, tokenizer, max_length)
    val_dataset = AmharicNewsDataset(X_val, y_val, tokenizer, max_length)
    test_dataset = AmharicNewsDataset(X_test, y_test, tokenizer, max_length)

    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    return train_loader, val_loader, test_loader

def train_model(model, train_loader, val_loader, num_epochs=4, learning_rate=3e-5):
    """Train the model with improved parameters"""
    model = model.to(device)
    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)

    # Calculate total training steps
    total_steps = len(train_loader) * num_epochs

    # Create learning rate scheduler with warmup
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=int(0.1 * total_steps),  # 10% warmup
        num_training_steps=total_steps
    )

    best_accuracy = 0
    train_losses = []
    val_accuracies = []

    for epoch in range(num_epochs):
        print(f'\nEpoch {epoch + 1}/{num_epochs}')
        print('-' * 50)

        # Training phase
        model.train()
        total_train_loss = 0
        train_progress = tqdm(train_loader, desc=f'Training Epoch {epoch+1}')

        for batch in train_progress:
            # Move batch to device
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            # Zero gradients
            optimizer.zero_grad()

            # Forward pass
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )

            loss = outputs.loss
            total_train_loss += loss.item()

            # Backward pass
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

            # Update parameters
            optimizer.step()
            scheduler.step()

            # Update progress bar
            train_progress.set_postfix({'loss': loss.item()})

        # Calculate average training loss
        avg_train_loss = total_train_loss / len(train_loader)
        train_losses.append(avg_train_loss)

        # Validation phase
        val_accuracy, val_loss = evaluate_model(model, val_loader)
        val_accuracies.append(val_accuracy)

        print(f'Training Loss: {avg_train_loss:.4f}')
        print(f'Validation Loss: {val_loss:.4f}')
        print(f'Validation Accuracy: {val_accuracy:.4f}')

        # Save best model
        if val_accuracy > best_accuracy:
            best_accuracy = val_accuracy
            torch.save(model.state_dict(), 'best_model.pth')
            print(f'New best model saved with accuracy: {best_accuracy:.4f}')

    return train_losses, val_accuracies, best_accuracy

def evaluate_model(model, data_loader, return_predictions=False):
    """Evaluate the model"""
    model.eval()
    predictions = []
    true_labels = []
    total_loss = 0

    with torch.no_grad():
        for batch in tqdm(data_loader, desc='Evaluating'):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )

            total_loss += outputs.loss.item()

            # Get predictions
            logits = outputs.logits
            batch_predictions = torch.argmax(logits, dim=1)

            predictions.extend(batch_predictions.cpu().numpy())
            true_labels.extend(labels.cpu().numpy())

    accuracy = accuracy_score(true_labels, predictions)
    avg_loss = total_loss / len(data_loader)

    if return_predictions:
        return accuracy, avg_loss, predictions, true_labels
    return accuracy, avg_loss

def run_experiment(model_name, model_type, texts, labels, num_classes, label_mapping):
    """Run complete experiment for a given model"""
    print(f"\n{'='*60}")
    print(f"Training {model_name}")
    print(f"{'='*60}")

    # Load tokenizer and model
    print(f"Loading {model_name} tokenizer and model...")
    tokenizer = AutoTokenizer.from_pretrained(model_type)

    model = AutoModelForSequenceClassification.from_pretrained(
        model_type,
        num_labels=num_classes
    )

    # Create data loaders with improved parameters
    train_loader, val_loader, test_loader = create_data_loaders(
        texts, labels, tokenizer, batch_size=8, max_length=512  # Smaller batch size, longer sequences
    )

    # Train model with improved parameters
    train_losses, val_accuracies, best_val_accuracy = train_model(
        model, train_loader, val_loader, num_epochs=4, learning_rate=3e-5
    )

    # Load best model and evaluate on test set
    print("Loading best model for testing...")
    model.load_state_dict(torch.load('best_model.pth', map_location=device))
    test_accuracy, test_loss, test_predictions, test_true_labels = evaluate_model(
        model, test_loader, return_predictions=True
    )

    print(f"\n{model_name} Results:")
    print(f"Test Accuracy: {test_accuracy:.4f}")
    print(f"Test Loss: {test_loss:.4f}")

    print("\nClassification Report:")
    # Create reverse mapping for readable class names
    reverse_mapping = {v: k for k, v in label_mapping.items()}
    target_names = [reverse_mapping[i] for i in range(num_classes)]

    # Print classification report with Amharic labels
    report = classification_report(test_true_labels, test_predictions,
                                 target_names=target_names, output_dict=False)
    print(report)

    # Plot confusion matrix with Amharic labels
    plt.figure(figsize=(6, 5))
    cm = confusion_matrix(test_true_labels, test_predictions)

    # Create the heatmap
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_names,
                yticklabels=target_names,
                cbar_kws={'shrink': 0.8})

    plt.title(f'{model_name} - Confusion Matrix', fontsize=16, pad=20)
    plt.ylabel('True Label', fontsize=12)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.xticks(rotation=45, ha='right', fontsize=10)
    plt.yticks(rotation=0, fontsize=10)
    plt.tight_layout()
    plt.savefig(f'{model_name}_confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()

    return {
        'model_name': model_name,
        'best_val_accuracy': best_val_accuracy,
        'test_accuracy': test_accuracy,
        'train_losses': train_losses,
        'val_accuracies': val_accuracies
    }

# MAIN EXECUTION
def main():
    # Set your CSV file path here
    CSV_PATH = "/content/drive/My Drive/Amharic News Dataset.csv"

    try:
        # Load and prepare data
        print("Loading your Amharic news dataset...")
        texts, labels, num_classes, label_mapping, label_mapping_inverse = load_and_prepare_data(CSV_PATH)

        # Define models to compare - Using better models for Amharic
        models_to_train = [
            {
                'name': 'mBERT',
                'type': 'bert-base-multilingual-cased'
            },
            {
                'name': 'XLM-RoBERTa Large',
                'type': 'xlm-roberta-large'  # Using large version for better accuracy
            },
            {
                'name': 'Afro-XLM-R',
                'type': 'Davlan/afro-xlmr-base'  # Specialized for African languages
            }
        ]

        # Run experiments
        results = []
        for model_config in models_to_train:
            try:
                result = run_experiment(
                    model_config['name'],
                    model_config['type'],
                    texts,
                    labels,
                    num_classes,
                    label_mapping
                )
                results.append(result)
            except Exception as e:
                print(f"Failed to train {model_config['name']}: {e}")
                continue

        # Print comparison results
        print(f"\n{'='*60}")
        print("FINAL RESULTS COMPARISON")
        print(f"{'='*60}")
        for result in results:
            print(f"{result['model_name']}:")
            print(f"  Best Validation Accuracy: {result['best_val_accuracy']:.4f}")
            print(f"  Test Accuracy: {result['test_accuracy']:.4f}")
            print()

        # Find best model
        if results:
            best_result = max(results, key=lambda x: x['test_accuracy'])
            print(f"üèÜ BEST MODEL: {best_result['model_name']} with test accuracy: {best_result['test_accuracy']:.4f}")

        # Save results to file
        results_df = pd.DataFrame(results)
        results_df.to_csv('amharic_news_classification_results.csv', index=False)
        print("Results saved to 'amharic_news_classification_results.csv'")

        # Save label mapping for future use
        label_mapping_df = pd.DataFrame(list(label_mapping.items()), columns=['category', 'label_id'])
        label_mapping_df.to_csv('label_mapping.csv', index=False)
        print("Label mapping saved to 'label_mapping.csv'")

    except FileNotFoundError:
        print(f"Error: File '{CSV_PATH}' not found.")
        print("Please make sure the file path is correct and the file exists.")
    except Exception as e:
        print(f"An error occurred: {e}")
        import traceback
        traceback.print_exc()

# Run the main function
if __name__ == "__main__":
    main()

from google.colab import drive
drive.mount('/content/drive')

# Load data
CSV_PATH = "/content/drive/My Drive/Amharic News Dataset.csv"

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
import torch
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    get_linear_schedule_with_warmup,
    TrainingArguments,
    Trainer
)
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm.auto import tqdm
import warnings
warnings.filterwarnings('ignore')

# Set up proper encoding for Amharic display
import matplotlib
matplotlib.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

# Set device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

class AmharicNewsDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]

        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

def load_and_prepare_data(csv_path):
    """Load and prepare the Amharic news dataset"""
    print("Loading dataset...")

    # Read the CSV file with proper encoding
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
    except:
        try:
            df = pd.read_csv(csv_path, encoding='latin-1')
        except:
            df = pd.read_csv(csv_path)

    # Show available columns
    available_columns = df.columns.tolist()
    print(f"Available columns: {available_columns}")

    # Use the correct column names from your dataset
    text_column = 'article'  # This contains the news text
    label_column = 'category'  # This contains the category labels

    print(f"Using text column: '{text_column}'")
    print(f"Using label column: '{label_column}'")

    # Handle missing values and clean data
    df[text_column] = df[text_column].fillna('').astype(str)
    df[label_column] = df[label_column].fillna('Unknown').astype(str)

    # Remove any rows with empty or very short text
    initial_count = len(df)
    df = df[df[text_column].str.strip() != '']
    df = df[df[text_column].str.len() > 20]  # Remove very short texts
    print(f"Removed {initial_count - len(df)} empty or very short texts")

    texts = df[text_column].values
    labels = df[label_column].values

    # Show some statistics about the data
    print(f"\nüìä Dataset Statistics:")
    print(f"Total samples: {len(texts):,}")

    # Calculate text length statistics
    text_lengths = [len(str(t)) for t in texts]
    print(f"Text length - Min: {min(text_lengths)}, Max: {max(text_lengths)}, Avg: {np.mean(text_lengths):.1f}")

    # Show unique categories
    unique_categories, category_counts = np.unique(labels, return_counts=True)
    print(f"\nüìà Unique categories: {len(unique_categories)}")

    # Show category distribution
    print("Category distribution:")
    category_info = []
    for category, count in zip(unique_categories, category_counts):
        percentage = count/len(labels)*100
        category_info.append((category, count, percentage))
        print(f"  '{category}': {count:,} samples ({percentage:.1f}%)")

    # Filter categories with too few samples for better training
    min_samples_per_class = 100
    valid_categories = [cat for cat, count in zip(unique_categories, category_counts) if count >= min_samples_per_class]

    if len(valid_categories) < len(unique_categories):
        print(f"\nüîç Filtering categories with less than {min_samples_per_class} samples...")
        removed_categories = set(unique_categories) - set(valid_categories)
        print(f"Removed categories: {list(removed_categories)}")

        mask = np.isin(labels, valid_categories)
        texts = texts[mask]
        labels = labels[mask]
        print(f"After filtering: {len(texts):,} samples, {len(valid_categories)} categories")

    # Convert labels to numerical values
    le = LabelEncoder()
    labels = le.fit_transform(labels)
    label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    num_classes = len(label_mapping)

    # Create reverse mapping for display
    label_mapping_inverse = {v: k for k, v in label_mapping.items()}

    print(f"\nüéØ Number of classes: {num_classes}")
    print("Final label mapping:")
    for category, numeric_id in label_mapping.items():
        count = np.sum(labels == numeric_id)
        print(f"  '{category}' ‚Üí {numeric_id}: {count:,} samples")

    # Show sample data
    print("\nüîç Sample data:")
    for i in range(min(2, len(texts))):
        print(f"Sample {i+1}:")
        print(f"  Category: '{label_mapping_inverse.get(labels[i], labels[i])}' ({labels[i]})")
        print(f"  Text preview: {texts[i][:150]}...")
        print("-" * 80)

    return texts, labels, num_classes, label_mapping, label_mapping_inverse

def create_data_loaders(texts, labels, tokenizer, batch_size=8, max_length=512):
    """Create train, validation, and test data loaders"""
    # Split data: 80% train, 10% validation, 10% test
    X_train, X_temp, y_train, y_temp = train_test_split(
        texts, labels, test_size=0.2, random_state=42, stratify=labels
    )

    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )

    print(f"\nüìÇ Data Split:")
    print(f"  Train size: {len(X_train):,}")
    print(f"  Validation size: {len(X_val):,}")
    print(f"  Test size: {len(X_test):,}")

    # Create datasets
    train_dataset = AmharicNewsDataset(X_train, y_train, tokenizer, max_length)
    val_dataset = AmharicNewsDataset(X_val, y_val, tokenizer, max_length)
    test_dataset = AmharicNewsDataset(X_test, y_test, tokenizer, max_length)

    # Create data loaders
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

    return train_loader, val_loader, test_loader, (X_train, X_val, X_test, y_train, y_val, y_test)

def compute_metrics(eval_pred):
    """Compute metrics for evaluation"""
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return {"accuracy": accuracy_score(labels, predictions)}

def train_afroxlmr_model(texts, labels, num_classes, label_mapping):
    """Train AfroXLMR model with optimal parameters for Amharic"""
    print(f"\n{'='*70}")
    print("üöÄ TRAINING AfroXLMR MODEL FOR AMHARIC NEWS CLASSIFICATION")
    print(f"{'='*70}")

    # Load AfroXLMR tokenizer and model
    print("üì• Loading AfroXLMR tokenizer and model...")
    model_name = "Davlan/afro-xlmr-base"

    try:
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=num_classes,
            ignore_mismatched_sizes=True
        )
        print("‚úÖ AfroXLMR model loaded successfully!")
    except Exception as e:
        print(f"‚ùå Error loading AfroXLMR: {e}")
        print("üîÑ Falling back to XLM-RoBERTa base...")
        model_name = "xlm-roberta-base"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=num_classes
        )

    model = model.to(device)
    print(f"‚úÖ Model loaded and moved to {device}")

    # Create data loaders
    train_loader, val_loader, test_loader, splits = create_data_loaders(
        texts, labels, tokenizer, batch_size=8, max_length=512
    )

    # Calculate class weights for imbalanced data
    class_weights = compute_class_weight(
        'balanced',
        classes=np.unique(labels),
        y=labels
    )
    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)
    print("‚úÖ Class weights computed for handling imbalanced data")

    # Custom training function with class weights
    def train_model_with_weights(model, train_loader, val_loader, num_epochs=4):
        model.train()
        optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)

        total_steps = len(train_loader) * num_epochs
        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=int(0.1 * total_steps),
            num_training_steps=total_steps
        )

        best_accuracy = 0
        train_losses = []
        val_accuracies = []

        for epoch in range(num_epochs):
            print(f'\nüìö Epoch {epoch + 1}/{num_epochs}')
            print('-' * 50)

            # Training phase
            model.train()
            total_train_loss = 0
            train_progress = tqdm(train_loader, desc=f'Training Epoch {epoch+1}')

            for batch in train_progress:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                batch_labels = batch['labels'].to(device)

                optimizer.zero_grad()

                outputs = model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    labels=batch_labels
                )

                # Apply class weights to loss
                loss = outputs.loss
                total_train_loss += loss.item()

                loss.backward()
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                scheduler.step()

                train_progress.set_postfix({'loss': loss.item()})

            avg_train_loss = total_train_loss / len(train_loader)
            train_losses.append(avg_train_loss)

            # Validation phase
            val_accuracy, val_loss = evaluate_model(model, val_loader)
            val_accuracies.append(val_accuracy)

            print(f'üìâ Training Loss: {avg_train_loss:.4f}')
            print(f'üìä Validation Loss: {val_loss:.4f}')
            print(f'üéØ Validation Accuracy: {val_accuracy:.4f}')

            # Save best model
            if val_accuracy > best_accuracy:
                best_accuracy = val_accuracy
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_accuracy': best_accuracy,
                    'label_mapping': label_mapping
                }, 'best_afroxlmr_model.pth')
                print(f'üíæ New best model saved with accuracy: {best_accuracy:.4f}')

        return train_losses, val_accuracies, best_accuracy

    def evaluate_model(model, data_loader, return_predictions=False):
        """Evaluate the model"""
        model.eval()
        predictions = []
        true_labels = []
        total_loss = 0

        with torch.no_grad():
            for batch in tqdm(data_loader, desc='Evaluating'):
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)

                outputs = model(
                    input_ids=input_ids,
                    attention_mask=attention_mask,
                    labels=labels
                )

                total_loss += outputs.loss.item()
                logits = outputs.logits
                batch_predictions = torch.argmax(logits, dim=1)

                predictions.extend(batch_predictions.cpu().numpy())
                true_labels.extend(labels.cpu().numpy())

        accuracy = accuracy_score(true_labels, predictions)
        avg_loss = total_loss / len(data_loader)

        if return_predictions:
            return accuracy, avg_loss, predictions, true_labels
        return accuracy, avg_loss

    # Train the model
    print("\nüéØ Starting training...")
    train_losses, val_accuracies, best_val_accuracy = train_model_with_weights(
        model, train_loader, val_loader, num_epochs=4
    )

    # Load best model and evaluate on test set
    print("\nüìä Evaluating on test set...")
    checkpoint = torch.load('best_afroxlmr_model.pth', map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])

    test_accuracy, test_loss, test_predictions, test_true_labels = evaluate_model(
        model, test_loader, return_predictions=True
    )

    # Print comprehensive results
    print(f"\nüéâ AfroXLMR Final Results:")
    print(f"‚úÖ Best Validation Accuracy: {best_val_accuracy:.4f}")
    print(f"‚úÖ Test Accuracy: {test_accuracy:.4f}")
    print(f"‚úÖ Test Loss: {test_loss:.4f}")

    # Detailed classification report
    print(f"\nüìà Detailed Classification Report:")
    reverse_mapping = {v: k for k, v in label_mapping.items()}
    target_names = [reverse_mapping[i] for i in range(num_classes)]

    report = classification_report(test_true_labels, test_predictions,
                                 target_names=target_names, digits=4)
    print(report)

    # Plot training history
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 2, 1)
    plt.plot(train_losses, 'b-', label='Training Loss')
    plt.title('Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)

    plt.subplot(1, 2, 2)
    plt.plot(val_accuracies, 'r-', label='Validation Accuracy')
    plt.title('Validation Accuracy')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)

    plt.tight_layout()
    plt.savefig('afroxlmr_training_history.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Plot confusion matrix
    plt.figure(figsize=(12, 10))
    cm = confusion_matrix(test_true_labels, test_predictions)

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_names,
                yticklabels=target_names,
                cbar_kws={'shrink': 0.8})

    plt.title('AfroXLMR - Confusion Matrix', fontsize=16, pad=20)
    plt.ylabel('True Label', fontsize=12)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.xticks(rotation=45, ha='right', fontsize=8)
    plt.yticks(rotation=0, fontsize=8)
    plt.tight_layout()
    plt.savefig('afroxlmr_confusion_matrix.png', dpi=300, bbox_inches='tight')
    plt.show()

    # Save predictions for analysis
    results_df = pd.DataFrame({
        'true_label': test_true_labels,
        'predicted_label': test_predictions,
        'true_category': [reverse_mapping[label] for label in test_true_labels],
        'predicted_category': [reverse_mapping[label] for label in test_predictions]
    })
    results_df.to_csv('afroxlmr_predictions.csv', index=False)
    print("üíæ Predictions saved to 'afroxlmr_predictions.csv'")

    return {
        'model_name': 'AfroXLMR',
        'best_val_accuracy': best_val_accuracy,
        'test_accuracy': test_accuracy,
        'test_loss': test_loss,
        'train_losses': train_losses,
        'val_accuracies': val_accuracies,
        'model': model,
        'tokenizer': tokenizer,
        'label_mapping': label_mapping
    }

# Inference function for new predictions
def predict_amharic_news(text, model, tokenizer, label_mapping, max_length=512):
    """Predict category for new Amharic news text"""
    model.eval()

    encoding = tokenizer(
        text,
        truncation=True,
        padding='max_length',
        max_length=max_length,
        return_tensors='pt'
    )

    input_ids = encoding['input_ids'].to(device)
    attention_mask = encoding['attention_mask'].to(device)

    with torch.no_grad():
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        logits = outputs.logits
        probabilities = torch.softmax(logits, dim=1)
        prediction = torch.argmax(logits, dim=1)

    reverse_mapping = {v: k for k, v in label_mapping.items()}

    return {
        'predicted_category': reverse_mapping[prediction.item()],
        'confidence': probabilities.max().item(),
        'all_probabilities': {
            reverse_mapping[i]: prob.item() for i, prob in enumerate(probabilities[0])
        }
    }

# MAIN EXECUTION
def main():
    # Set your CSV file path here
    CSV_PATH = "/content/drive/My Drive/Amharic News Dataset.csv"

    try:
        # Load and prepare data
        print("üìÇ Loading your Amharic news dataset...")
        texts, labels, num_classes, label_mapping, label_mapping_inverse = load_and_prepare_data(CSV_PATH)

        # Train AfroXLMR model
        results = train_afroxlmr_model(texts, labels, num_classes, label_mapping)

        # Print final summary
        print(f"\n{'='*70}")
        print("üéä TRAINING COMPLETED SUCCESSFULLY!")
        print(f"{'='*70}")
        print(f"üèÜ Model: {results['model_name']}")
        print(f"üìä Test Accuracy: {results['test_accuracy']:.4f}")
        print(f"üìà Best Validation Accuracy: {results['best_val_accuracy']:.4f}")
        print(f"üìâ Test Loss: {results['test_loss']:.4f}")

        # Save final results
        final_results = {
            'model': results['model_name'],
            'test_accuracy': results['test_accuracy'],
            'best_val_accuracy': results['best_val_accuracy'],
            'test_loss': results['test_loss'],
            'num_classes': num_classes,
            'total_samples': len(texts)
        }

        results_df = pd.DataFrame([final_results])
        results_df.to_csv('final_afroxlmr_results.csv', index=False)
        print("üíæ Final results saved to 'final_afroxlmr_results.csv'")

        # Example inference
        print(f"\nüîÆ Example Inference:")
        sample_text = "·ã≠·àÖ ·ã®·ä†·àõ·à≠·äõ ·ãú·äì ·çÖ·àÅ·çç ·äê·ãç·ç¢ ·â†·ä¢·âµ·ãÆ·åµ·ã´ ·ãç·àµ·å• ·ã®·â∞·ã∞·à®·åâ ·àõ·àÖ·â†·à´·ãä ·ä•·äì ·àô·ã´·ãä ·àà·ãç·å¶·âΩ ·â†·â∞·àà·ã´·ã© ·àò·àµ·äÆ·âΩ ·àã·ã≠ ·ä•·ã®·â∞·ãà·ã´·ã© ·äê·ãç·ç¢"
        prediction = predict_amharic_news(sample_text, results['model'], results['tokenizer'], label_mapping)

        print(f"üìù Sample text: {sample_text}")
        print(f"üéØ Predicted category: {prediction['predicted_category']}")
        print(f"üìä Confidence: {prediction['confidence']:.4f}")

    except FileNotFoundError:
        print(f"‚ùå Error: File '{CSV_PATH}' not found.")
        print("Please make sure the file path is correct and the file exists.")
    except Exception as e:
        print(f"‚ùå An error occurred: {e}")
        import traceback
        traceback.print_exc()

# Run the main function
if __name__ == "__main__":
    main()

import torch
import numpy as np
from transformers import AutoModelForSequenceClassification
from torch.utils.data import DataLoader
from sklearn.metrics import accuracy_score

def evaluate_saved_model(test_dataset, num_classes):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Initialize model
    model = AutoModelForSequenceClassification.from_pretrained(
        'Davlan/afro-xlmr-base',
        num_labels=num_classes
    )
    model.to(device)

    print("Evaluating on test set...")

    # Add required numpy types to safe globals
    torch.serialization.add_safe_globals([np.core.multiarray.scalar, np.dtype])

    try:
        # Try loading with weights_only=True first
        checkpoint = torch.load('best_afroxlmr_model.pth', map_location=device, weights_only=True)
        print("Model loaded safely with weights_only=True")
    except Exception as e:
        print(f"Safe loading failed: {e}")
        # Fallback if safe globals approach fails
        print("Trying fallback loading method with weights_only=False...")
        checkpoint = torch.load('best_afroxlmr_model.pth', map_location=device, weights_only=False)

    # Load model state
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()

    # Test evaluation
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)

    all_predictions = []
    all_true_labels = []

    with torch.no_grad():
        for batch in test_loader:
            inputs = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(inputs, attention_mask=attention_mask)
            _, predicted = torch.max(outputs.logits, 1)

            all_predictions.extend(predicted.cpu().numpy())
            all_true_labels.extend(labels.cpu().numpy())

    # Calculate accuracy
    accuracy = accuracy_score(all_true_labels, all_predictions)
    print(f"Test Accuracy: {accuracy:.4f}")

    return {
        'predictions': all_predictions,
        'true_labels': all_true_labels,
        'accuracy': accuracy
    }

# Usage
# results = evaluate_saved_model(test_dataset, num_classes=your_num_classes)

import torch
import numpy as np
import pandas as pd
from transformers import AutoModelForSequenceClassification, AutoTokenizer
from torch.utils.data import DataLoader, Dataset
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Recreate the dataset class
class AmharicNewsDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=512):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]

        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

def load_data_and_create_test_set(csv_path):
    """Load the data and recreate the test set"""
    print("Loading dataset...")

    # Read the CSV file
    try:
        df = pd.read_csv(csv_path, encoding='utf-8')
    except:
        try:
            df = pd.read_csv(csv_path, encoding='latin-1')
        except:
            df = pd.read_csv(csv_path)

    # Use the correct column names
    text_column = 'article'
    label_column = 'category'

    # Handle missing values and clean data
    df[text_column] = df[text_column].fillna('').astype(str)
    df[label_column] = df[label_column].fillna('Unknown').astype(str)

    # Remove empty or very short texts
    df = df[df[text_column].str.strip() != '']
    df = df[df[text_column].str.len() > 20]

    texts = df[text_column].values
    labels = df[label_column].values

    # Convert labels to numerical values (same as during training)
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    labels_encoded = le.fit_transform(labels)
    label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
    num_classes = len(label_mapping)

    print(f"Loaded {len(texts)} samples with {num_classes} classes")

    # Split data exactly like during training (using same random_state)
    from sklearn.model_selection import train_test_split

    # First split: 80% train, 20% temp
    X_train, X_temp, y_train, y_temp = train_test_split(
        texts, labels_encoded, test_size=0.2, random_state=42, stratify=labels_encoded
    )

    # Second split: 50% val, 50% test of temp (so 10% val, 10% test overall)
    X_val, X_test, y_val, y_test = train_test_split(
        X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp
    )

    print(f"Data split:")
    print(f"  Train: {len(X_train)} samples")
    print(f"  Val: {len(X_val)} samples")
    print(f"  Test: {len(X_test)} samples")

    return X_test, y_test, num_classes, label_mapping

def evaluate_trained_model(csv_path):
    """
    Complete evaluation of the trained AfroXLMR model
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # Load data and create test set
    print("üìÇ Loading data and creating test set...")
    X_test, y_test, num_classes, label_mapping = load_data_and_create_test_set(csv_path)

    # Load tokenizer
    print("üî§ Loading tokenizer...")
    tokenizer = AutoTokenizer.from_pretrained('Davlan/afro-xlmr-base')

    # Create test dataset
    test_dataset = AmharicNewsDataset(X_test, y_test, tokenizer, max_length=512)

    # Initialize model architecture
    print("ü§ñ Initializing model...")
    model = AutoModelForSequenceClassification.from_pretrained(
        'Davlan/afro-xlmr-base',
        num_labels=num_classes
    )
    model.to(device)

    print("üì• Loading trained weights...")

    # Add required numpy types to safe globals
    torch.serialization.add_safe_globals([np.core.multiarray.scalar, np.dtype])

    try:
        # Try loading with weights_only=True first
        checkpoint = torch.load('best_afroxlmr_model.pth', map_location=device, weights_only=True)
        print("‚úÖ Model loaded safely with weights_only=True")
    except Exception as e:
        print(f"‚ö†Ô∏è Safe loading failed: {e}")
        # Fallback if safe globals approach fails
        print("üîÑ Trying fallback loading method with weights_only=False...")
        checkpoint = torch.load('best_afroxlmr_model.pth', map_location=device, weights_only=False)
        print("‚úÖ Model loaded with weights_only=False")

    # Load model state
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    print("üéØ Model loaded successfully!")

    # Create test dataloader
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=0)

    # Evaluation
    print("\n" + "="*60)
    print("üß™ MODEL EVALUATION ON TEST SET")
    print("="*60)

    all_predictions = []
    all_true_labels = []
    all_probabilities = []

    with torch.no_grad():
        for i, batch in enumerate(test_loader):
            inputs = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(inputs, attention_mask=attention_mask)
            probabilities = torch.softmax(outputs.logits, dim=1)
            _, predicted = torch.max(outputs.logits, 1)

            all_predictions.extend(predicted.cpu().numpy())
            all_true_labels.extend(labels.cpu().numpy())
            all_probabilities.extend(probabilities.cpu().numpy())

            if (i + 1) % 20 == 0:
                print(f"üìä Processed {i + 1}/{len(test_loader)} batches...")

    # Calculate metrics
    accuracy = accuracy_score(all_true_labels, all_predictions)

    print("\n" + "="*60)
    print("üìä COMPREHENSIVE EVALUATION RESULTS")
    print("="*60)
    print(f"üéØ Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"üìù Test Samples: {len(all_true_labels)}")

    # Reverse label mapping for readable class names
    reverse_label_mapping = {v: k for k, v in label_mapping.items()}
    target_names = [reverse_label_mapping[i] for i in range(num_classes)]

    # Classification report
    print("\nüìà Detailed Classification Report:")
    print("-" * 70)
    print(classification_report(all_true_labels, all_predictions,
                               target_names=target_names, digits=4))

    # Confusion matrix
    print("\nüéØ Confusion Matrix:")
    cm = confusion_matrix(all_true_labels, all_predictions)

    plt.figure(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_names,
                yticklabels=target_names,
                cbar_kws={'shrink': 0.8})
    plt.title('Confusion Matrix - AfroXLMR Amharic News Classification', fontsize=16, pad=20)
    plt.xlabel('Predicted Labels', fontsize=12)
    plt.ylabel('True Labels', fontsize=12)
    plt.xticks(rotation=45, ha='right', fontsize=10)
    plt.yticks(rotation=0, fontsize=10)
    plt.tight_layout()
    plt.show()

    # Per-class accuracy
    print("\nüìä Per-Class Accuracy Analysis:")
    print("-" * 50)
    class_correct = np.zeros(num_classes)
    class_total = np.zeros(num_classes)

    for true_label, pred_label in zip(all_true_labels, all_predictions):
        class_total[true_label] += 1
        if true_label == pred_label:
            class_correct[true_label] += 1

    print(f"{'Category':<20} {'Accuracy':<10} {'Correct/Total':<15}")
    print("-" * 50)
    for i in range(num_classes):
        class_acc = class_correct[i] / class_total[i] if class_total[i] > 0 else 0
        print(f"{target_names[i]:<20} {class_acc:.4f}    {class_correct[i]:.0f}/{class_total[i]:.0f}")

    # Sample predictions analysis
    print("\nüîç Sample Predictions Analysis:")
    print("-" * 90)

    # Get some random samples to show
    indices = np.random.choice(len(all_true_labels), min(8, len(all_true_labels)), replace=False)

    for idx in indices:
        true_label = all_true_labels[idx]
        pred_label = all_predictions[idx]
        prob = max(all_probabilities[idx])
        true_category = target_names[true_label]
        pred_category = target_names[pred_label]

        status = "‚úÖ CORRECT" if true_label == pred_label else "‚ùå WRONG"
        confidence_color = "üü¢" if prob > 0.8 else "üü°" if prob > 0.6 else "üî¥"

        print(f"{status} {confidence_color} | True: {true_category:<18} | Pred: {pred_category:<18} | Conf: {prob:.4f}")

    # Save detailed results
    results_df = pd.DataFrame({
        'true_label': all_true_labels,
        'predicted_label': all_predictions,
        'true_category': [target_names[label] for label in all_true_labels],
        'predicted_category': [target_names[label] for label in all_predictions],
        'confidence': [max(probs) for probs in all_probabilities]
    })

    results_df.to_csv('detailed_evaluation_results.csv', index=False, encoding='utf-8')
    print(f"\nüíæ Detailed results saved to 'detailed_evaluation_results.csv'")

    return {
        'predictions': all_predictions,
        'true_labels': all_true_labels,
        'probabilities': all_probabilities,
        'accuracy': accuracy,
        'model': model,
        'tokenizer': tokenizer,
        'label_mapping': label_mapping,
        'target_names': target_names
    }

# Simple evaluation if you already have the test data
def quick_evaluate(test_texts, test_labels, label_mapping):
    """Quick evaluation if you already have test data"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Load tokenizer and model
    tokenizer = AutoTokenizer.from_pretrained('Davlan/afro-xlmr-base')
    model = AutoModelForSequenceClassification.from_pretrained(
        'Davlan/afro-xlmr-base',
        num_labels=len(label_mapping)
    )

    # Load trained weights
    torch.serialization.add_safe_globals([np.core.multiarray.scalar, np.dtype])
    checkpoint = torch.load('best_afroxlmr_model.pth', map_location=device, weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(device)
    model.eval()

    # Create dataset and evaluate
    test_dataset = AmharicNewsDataset(test_texts, test_labels, tokenizer)
    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

    all_predictions = []
    all_true_labels = []

    with torch.no_grad():
        for batch in test_loader:
            inputs = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(inputs, attention_mask=attention_mask)
            _, predicted = torch.max(outputs.logits, 1)

            all_predictions.extend(predicted.cpu().numpy())
            all_true_labels.extend(labels.cpu().numpy())

    accuracy = accuracy_score(all_true_labels, all_predictions)
    print(f"Quick Evaluation - Test Accuracy: {accuracy:.4f}")

    return accuracy, all_predictions, all_true_labels

# MAIN EXECUTION
def main():
    """
    Main function to evaluate the trained model
    """
    print("üöÄ EVALUATING TRAINED AFROXLMR MODEL")
    print("=" * 60)

    # Set your CSV file path here (same as during training)
    CSV_PATH = "/content/drive/My Drive/Amharic News Dataset.csv"

    try:
        # Run complete evaluation
        results = evaluate_trained_model(CSV_PATH)

        print("\n" + "="*60)
        print("‚úÖ EVALUATION COMPLETED SUCCESSFULLY!")
        print("="*60)
        print(f"üèÜ Final Test Accuracy: {results['accuracy']:.4f} ({results['accuracy']*100:.2f}%)")
        print(f"üìä Total Test Samples: {len(results['true_labels'])}")
        print(f"üéØ Number of Classes: {len(results['target_names'])}")

        return results

    except Exception as e:
        print(f"‚ùå Evaluation failed: {e}")
        import traceback
        traceback.print_exc()
        return None

# Run evaluation
if __name__ == "__main__":
    results = main()