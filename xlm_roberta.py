# -*- coding: utf-8 -*-
"""XLM-Roberta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sI-lPOlnLz8pgtw0jFLv5D35EH7K_yGd
"""

import re
import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder

def preprocess_amharic_text(text):
    """Preprocess Amharic text"""
    if pd.isna(text):
        return ""

    text = str(text)
    # Remove extra whitespace
    text = re.sub(r'\s+', ' ', text)
    # Remove special characters but keep Amharic characters
    text = re.sub(r'[^\w\s\u1200-\u137F]', ' ', text)
    return text.strip()

def prepare_amharic_dataset(file_path):
    """Enhanced dataset preparation for Amharic"""
    # Load data
    df = pd.read_csv(file_path)

    # Identify columns
    text_col = None
    label_col = None

    # Try to identify columns automatically
    possible_text_cols = ['article', 'text', 'content', 'body', 'news']
    possible_label_cols = ['category', 'label', 'class', 'type', 'topic']

    for col in possible_text_cols:
        if col in df.columns:
            text_col = col
            break

    for col in possible_label_cols:
        if col in df.columns:
            label_col = col
            break

    # If not found, use first two columns
    if text_col is None:
        text_col = df.columns[0]
    if label_col is None:
        label_col = df.columns[1]

    print(f"Using text column: '{text_col}'")
    print(f"Using label column: '{label_col}'")

    # Preprocess text
    df['cleaned_text'] = df[text_col].apply(preprocess_amharic_text)

    # Remove empty texts
    df = df[df['cleaned_text'].str.strip() != '']

    # Encode labels
    le = LabelEncoder()
    df['label_encoded'] = le.fit_transform(df[label_col])

    # Create mappings
    label2id = {label: idx for idx, label in enumerate(le.classes_)}
    id2label = {idx: label for label, idx in label2id.items()}

    print(f"\nDataset stats:")
    print(f"Total samples: {len(df)}")
    print(f"Number of classes: {len(label2id)}")
    print(f"Classes: {list(label2id.keys())}")

    return df, 'cleaned_text', label_col, label2id, id2label

# Quick test function
def quick_test_model():
    """Quick test with sample data if your dataset is not available"""
    print("Creating sample Amharic dataset for testing...")

    # Sample Amharic news data
    sample_data = {
        'article': [
            'የኢትዮጵያ ብሔራዊ ቡድን ከኬንያ ጋር ይጫወታል።',  # Sports
            'የገንዘብ ሚኒስትር አዲስ በጀት አቀረበ።',  # Politics
            'በአዲስ አበባ የቴክኖሎጂ ኮንፈርንስ ተጀመረ።',  # Technology
            'የአየር ንብረት ለውጥ ስለ ኢትዮጵያ ውይይት ተካሄደ።',  # Environment
            'አዲስ የህክምና መድሃኒት ተገኘ።',  # Health
        ],
        'category': ['Sports', 'Politics', 'Technology', 'Environment', 'Health']
    }

    df = pd.DataFrame(sample_data)

    # Save to CSV temporarily
    df.to_csv('/tmp/amharic_sample.csv', index=False)

    return '/tmp/amharic_sample.csv'

# Usage example:
if __name__ == "__main__":
    try:
        # Try to load your dataset
        file_path = "/content/drive/My Drive/Amharic News Dataset.csv"
        print("Loading your dataset...")

    except:
        print("Could not load your dataset. Creating sample dataset instead...")
        file_path = quick_test_model()

    # Use the enhanced preparation
    df, text_col, label_col, label2id, id2label = prepare_amharic_dataset(file_path)

    # Then continue with the training pipeline from the first code block
    # (Use the train_xlmr_amharic_classifier function with the prepared data)