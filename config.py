# -*- coding: utf-8 -*-
"""config.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fOw0NsJqYkhMwDXZ07oKoDFAEsrA3dJz
"""

"""
Configuration settings for Amharic News Classification Project
This file contains all hyperparameters, paths, and model configurations
"""

import os
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
import torch

# ============================================================================
# ENVIRONMENT SETTINGS
# ============================================================================

@dataclass
class EnvironmentConfig:
    """Environment and system configuration"""
    # Random seed for reproducibility
    SEED: int = 42

    # Device configuration
    DEVICE: str = "cuda" if torch.cuda.is_available() else "cpu"

    # Number of workers for data loading
    NUM_WORKERS: int = 4 if torch.cuda.is_available() else 2

    # Enable/disable mixed precision training (faster, less memory)
    USE_AMP: bool = True  # Automatic Mixed Precision

    # Enable/disable gradient accumulation
    USE_GRADIENT_ACCUMULATION: bool = True

    # Enable/disable gradient checkpointing (saves memory)
    USE_GRADIENT_CHECKPOINTING: bool = False

    # Logging level
    LOG_LEVEL: str = "INFO"  # DEBUG, INFO, WARNING, ERROR

    # Enable/disable wandb logging
    USE_WANDB: bool = False
    WANDB_PROJECT: str = "amharic-news-classification"
    WANDB_ENTITY: str = ""  # Your wandb username/team

# ============================================================================
# DATA CONFIGURATION
# ============================================================================

@dataclass
class DataConfig:
    """Dataset and preprocessing configuration"""
    # Dataset paths
    DATA_PATH: str = "data/amharic_news_dataset.csv"
    PROCESSED_DATA_DIR: str = "data/processed"

    # Column names in the dataset
    TEXT_COLUMN: str = "article"  # Main text column
    TEXT_COLUMN_ALTERNATIVES: List[str] = ["text", "content", "body", "news"]

    LABEL_COLUMN: str = "category"  # Label column
    LABEL_COLUMN_ALTERNATIVES: List[str] = ["label", "class", "type", "topic"]

    # Text preprocessing
    MAX_SEQUENCE_LENGTH: int = 256  # Maximum token length
    TRUNCATION: bool = True  # Truncate sequences longer than max_length
    PADDING: str = "max_length"  # Padding strategy

    # Train/validation/test splits
    TRAIN_SIZE: float = 0.7
    VAL_SIZE: float = 0.15
    TEST_SIZE: float = 0.15

    # Stratified splitting (preserve class distribution)
    STRATIFY_SPLIT: bool = True

    # Data augmentation (for text)
    USE_DATA_AUGMENTATION: bool = False
    AUGMENTATION_PROBABILITY: float = 0.3

    # Cache settings
    CACHE_DIR: str = "./cache"
    USE_CACHE: bool = True

# ============================================================================
# MODEL CONFIGURATIONS
# ============================================================================

@dataclass
class ModelConfig:
    """Base model configuration"""
    # Model saving/loading
    MODEL_SAVE_DIR: str = "models"
    MODEL_LOAD_FROM_CHECKPOINT: bool = False
    CHECKPOINT_PATH: str = ""

    # Training hyperparameters
    BATCH_SIZE: int = 16
    GRADIENT_ACCUMULATION_STEPS: int = 2
    NUM_EPOCHS: int = 5
    LEARNING_RATE: float = 2e-5
    WEIGHT_DECAY: float = 0.01
    WARMUP_RATIO: float = 0.1  # Percentage of training steps for warmup

    # Optimizer
    OPTIMIZER: str = "adamw"  # adamw, adam, sgd
    BETAS: Tuple[float, float] = (0.9, 0.999)
    EPS: float = 1e-8

    # Scheduler
    SCHEDULER: str = "linear"  # linear, cosine, constant
    NUM_WARMUP_STEPS: int = 0  # If 0, calculated from warmup_ratio

    # Gradient clipping
    MAX_GRAD_NORM: float = 1.0

    # Dropout (model specific)
    DROPOUT_PROB: float = 0.1
    ATTENTION_DROPOUT_PROB: float = 0.1
    HIDDEN_DROPOUT_PROB: float = 0.1

    # Early stopping
    USE_EARLY_STOPPING: bool = True
    EARLY_STOPPING_PATIENCE: int = 3
    EARLY_STOPPING_MIN_DELTA: float = 0.001

@dataclass
class MBertConfig(ModelConfig):
    """mBERT specific configuration"""
    MODEL_NAME: str = "bert-base-multilingual-cased"
    MODEL_TYPE: str = "bert"

    # mBERT specific parameters
    VOCAB_SIZE: int = 119547  # mBERT vocabulary size
    HIDDEN_SIZE: int = 768
    NUM_HIDDEN_LAYERS: int = 12
    NUM_ATTENTION_HEADS: int = 12
    INTERMEDIATE_SIZE: int = 3072

    # Training adjustments for mBERT
    LEARNING_RATE: float = 2e-5
    BATCH_SIZE: int = 16
    MAX_SEQUENCE_LENGTH: int = 256

    # Layer-wise learning rate decay
    USE_LAYERWISE_LR_DECAY: bool = False
    LAYERWISE_DECAY_RATE: float = 0.95

@dataclass
class XLMRobertaConfig(ModelConfig):
    """XLM-RoBERTa specific configuration"""
    MODEL_NAME: str = "xlm-roberta-base"
    MODEL_TYPE: str = "xlm-roberta"

    # XLM-R specific parameters
    VOCAB_SIZE: int = 250002  # XLM-R vocabulary size
    HIDDEN_SIZE: int = 768
    NUM_HIDDEN_LAYERS: int = 12
    NUM_ATTENTION_HEADS: int = 12
    INTERMEDIATE_SIZE: int = 3072

    # Training adjustments for XLM-R
    LEARNING_RATE: float = 1e-5  # Slightly lower LR for XLM-R
    BATCH_SIZE: int = 8  # Smaller batch size due to larger model
    MAX_SEQUENCE_LENGTH: int = 256

    # SentencePiece tokenizer settings
    SENTENCEPIECE_MODEL: str = "sentencepiece.bpe.model"
    USE_SENTENCEPIECE: bool = True

@dataclass
class AfroXLMRConfig(ModelConfig):
    """Afro-XLM-RoBERTa specific configuration"""
    MODEL_NAME: str = "castorini/afroxlmr-base"
    MODEL_TYPE: str = "xlm-roberta"

    # Afro-XLM-R specific parameters
    VOCAB_SIZE: int = 250002  # Same as XLM-R
    HIDDEN_SIZE: int = 768
    NUM_HIDDEN_LAYERS: int = 12
    NUM_ATTENTION_HEADS: int = 12
    INTERMEDIATE_SIZE: int = 3072

    # Training adjustments for Afro-XLM-R
    LEARNING_RATE: float = 3e-5  # Higher LR for fine-tuned model
    BATCH_SIZE: int = 16
    MAX_SEQUENCE_LENGTH: int = 256

    # African language specific settings
    USE_AFRICAN_LANG_ADAPTATION: bool = True
    LANG_ID: str = "amh"  # Amharic language code

# ============================================================================
# EVALUATION CONFIGURATION
# ============================================================================

@dataclass
class EvaluationConfig:
    """Evaluation and metrics configuration"""
    # Metrics to compute
    METRICS: List[str] = ["accuracy", "f1", "precision", "recall"]
    AVERAGE_METHOD: str = "weighted"  # macro, micro, weighted

    # Evaluation frequency
    EVAL_STEPS: int = 100  # Evaluate every N steps
    EVAL_EPOCH_END: bool = True  # Evaluate at end of each epoch

    # Save best model based on
    SAVE_BEST_BY: str = "f1"  # accuracy, f1, loss

    # Confusion matrix
    PLOT_CONFUSION_MATRIX: bool = True
    CONFUSION_MATRIX_SAVE_PATH: str = "results/confusion_matrices"

    # Classification report
    GENERATE_CLASSIFICATION_REPORT: bool = True
    REPORT_SAVE_PATH: str = "results/classification_reports"

    # Results saving
    RESULTS_DIR: str = "results"
    SAVE_PREDICTIONS: bool = True
    PREDICTIONS_FILE: str = "model_predictions.csv"

# ============================================================================
# EXPERIMENT TRACKING
# ============================================================================

@dataclass
class ExperimentConfig:
    """Experiment tracking and logging"""
    # Experiment name
    EXPERIMENT_NAME: str = "amharic_classification_experiment"

    # Versioning
    EXPERIMENT_VERSION: str = "v1.0"

    # Logging directories
    LOG_DIR: str = "logs"
    TENSORBOARD_DIR: str = "runs"

    # Checkpoint saving
    SAVE_CHECKPOINTS: bool = True
    CHECKPOINT_DIR: str = "checkpoints"
    SAVE_FREQUENCY: int = 1  # Save every N epochs

    # Model artifacts to save
    SAVE_TOKENIZER: bool = True
    SAVE_CONFIG: bool = True
    SAVE_MODEL_CARD: bool = True

    # Performance tracking
    TRACK_MEMORY_USAGE: bool = True
    TRACK_TRAINING_TIME: bool = True

# ============================================================================
# PREDICTION CONFIGURATION
# ============================================================================

@dataclass
class PredictionConfig:
    """Inference and prediction configuration"""
    # Model loading for inference
    INFERENCE_MODEL_PATH: str = "models/best_model"

    # Batch size for inference
    INFERENCE_BATCH_SIZE: int = 32

    # Output settings
    OUTPUT_PROBABILITIES: bool = True
    TOP_K_PREDICTIONS: int = 3
    CONFIDENCE_THRESHOLD: float = 0.5

    # Input preprocessing for inference
    PREPROCESS_INPUT: bool = True
    REMOVE_SPECIAL_CHARS: bool = True
    NORMALIZE_TEXT: bool = True

    # Cache predictions
    CACHE_PREDICTIONS: bool = True
    PREDICTION_CACHE_FILE: str = "cache/predictions_cache.pkl"

# ============================================================================
# PROJECT-WIDE CONFIGURATION
# ============================================================================

class ProjectConfig:
    """Main configuration class combining all configs"""

    def __init__(self, model_type: str = "mbert"):
        """
        Initialize configuration based on model type

        Args:
            model_type: One of 'mbert', 'xlmr', 'afroxlmr'
        """
        self.environment = EnvironmentConfig()
        self.data = DataConfig()
        self.evaluation = EvaluationConfig()
        self.experiment = ExperimentConfig()
        self.prediction = PredictionConfig()

        # Set model specific configuration
        if model_type.lower() == "mbert":
            self.model = MBertConfig()
        elif model_type.lower() == "xlmr":
            self.model = XLMRobertaConfig()
        elif model_type.lower() == "afroxlmr":
            self.model = AfroXLMRConfig()
        else:
            raise ValueError(f"Unknown model type: {model_type}. Choose from 'mbert', 'xlmr', 'afroxlmr'")

        # Update data config with model-specific sequence length
        self.data.MAX_SEQUENCE_LENGTH = self.model.MAX_SEQUENCE_LENGTH

        # Create directories
        self._create_directories()

    def _create_directories(self):
        """Create necessary directories for the project"""
        directories = [
            self.data.PROCESSED_DATA_DIR,
            self.data.CACHE_DIR,
            self.model.MODEL_SAVE_DIR,
            self.evaluation.RESULTS_DIR,
            self.evaluation.CONFUSION_MATRIX_SAVE_PATH,
            self.evaluation.REPORT_SAVE_PATH,
            self.experiment.LOG_DIR,
            self.experiment.CHECKPOINT_DIR,
            self.experiment.TENSORBOARD_DIR,
            self.prediction.PREDICTION_CACHE_FILE.rsplit('/', 1)[0]
        ]

        for directory in directories:
            if directory:  # Check if not empty string
                os.makedirs(directory, exist_ok=True)

    def get_model_save_path(self) -> str:
        """Get the full path for saving the model"""
        model_name = self.model.MODEL_NAME.split('/')[-1]
        return os.path.join(
            self.model.MODEL_SAVE_DIR,
            f"{model_name}_amharic_news"
        )

    def get_results_path(self, metric: str = None) -> str:
        """Get the path for saving results"""
        if metric:
            return os.path.join(
                self.evaluation.RESULTS_DIR,
                f"{self.model.MODEL_TYPE}_{metric}_results.json"
            )
        return os.path.join(
            self.evaluation.RESULTS_DIR,
            f"{self.model.MODEL_TYPE}_all_results.json"
        )

    def update_from_dict(self, config_dict: Dict):
        """Update configuration from dictionary"""
        for key, value in config_dict.items():
            if hasattr(self, key):
                setattr(self, key, value)
            elif hasattr(self.model, key):
                setattr(self.model, key, value)
            elif hasattr(self.data, key):
                setattr(self.data, key, value)

    def to_dict(self) -> Dict:
        """Convert configuration to dictionary"""
        config_dict = {}

        # Add all config sections
        config_dict['environment'] = self.environment.__dict__
        config_dict['data'] = self.data.__dict__
        config_dict['model'] = self.model.__dict__
        config_dict['evaluation'] = self.evaluation.__dict__
        config_dict['experiment'] = self.experiment.__dict__
        config_dict['prediction'] = self.prediction.__dict__

        return config_dict

    def save_config(self, filepath: str = "config.json"):
        """Save configuration to JSON file"""
        import json
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.to_dict(), f, indent=4, ensure_ascii=False)

    @classmethod
    def load_config(cls, filepath: str = "config.json"):
        """Load configuration from JSON file"""
        import json
        with open(filepath, 'r', encoding='utf-8') as f:
            config_dict = json.load(f)

        # Extract model type from config
        model_type = config_dict['model']['MODEL_TYPE']
        if 'xlm-roberta' in model_type.lower():
            model_type = 'xlmr' if 'afro' not in config_dict['model']['MODEL_NAME'] else 'afroxlmr'

        # Create config object
        config = cls(model_type=model_type)
        config.update_from_dict(config_dict)

        return config

# ============================================================================
# PRESET CONFIGURATIONS
# ============================================================================

def get_preset_config(preset_name: str = "default", model_type: str = "mbert") -> ProjectConfig:
    """
    Get preset configurations for different scenarios

    Args:
        preset_name: One of 'default', 'fast', 'accurate', 'lightweight'
        model_type: One of 'mbert', 'xlmr', 'afroxlmr'

    Returns:
        ProjectConfig with preset values
    """
    config = ProjectConfig(model_type=model_type)

    if preset_name == "fast":
        # Fast training for experimentation
        config.model.NUM_EPOCHS = 2
        config.model.BATCH_SIZE = 32
        config.data.MAX_SEQUENCE_LENGTH = 128
        config.evaluation.EVAL_STEPS = 50
        config.model.USE_EARLY_STOPPING = False

    elif preset_name == "accurate":
        # Maximum accuracy configuration
        config.model.NUM_EPOCHS = 10
        config.model.BATCH_SIZE = 8
        config.data.MAX_SEQUENCE_LENGTH = 512
        config.model.LEARNING_RATE = 1e-5
        config.model.USE_EARLY_STOPPING = True
        config.model.EARLY_STOPPING_PATIENCE = 5
        config.evaluation.EVAL_STEPS = 50

    elif preset_name == "lightweight":
        # Low memory configuration
        config.model.BATCH_SIZE = 4
        config.data.MAX_SEQUENCE_LENGTH = 128
        config.model.GRADIENT_ACCUMULATION_STEPS = 4
        config.model.USE_GRADIENT_CHECKPOINTING = True
        config.environment.USE_AMP = True

    elif preset_name == "production":
        # Production-ready configuration
        config.model.NUM_EPOCHS = 7
        config.model.BATCH_SIZE = 16
        config.data.MAX_SEQUENCE_LENGTH = 256
        config.model.USE_EARLY_STOPPING = True
        config.experiment.SAVE_MODEL_CARD = True
        config.evaluation.SAVE_PREDICTIONS = True

    return config

# ============================================================================
# DEFAULT CONFIGURATION
# ============================================================================

# Default configuration instance
default_config = ProjectConfig(model_type="mbert")

# Configuration for each model type
mbert_config = ProjectConfig(model_type="mbert")
xlmr_config = ProjectConfig(model_type="xlmr")
afroxlmr_config = ProjectConfig(model_type="afroxlmr")

# Export commonly used configurations
__all__ = [
    'ProjectConfig',
    'get_preset_config',
    'default_config',
    'mbert_config',
    'xlmr_config',
    'afroxlmr_config',
    'EnvironmentConfig',
    'DataConfig',
    'ModelConfig',
    'MBertConfig',
    'XLMRobertaConfig',
    'AfroXLMRConfig',
    'EvaluationConfig',
    'ExperimentConfig',
    'PredictionConfig'
]

# ============================================================================
# USAGE EXAMPLE
# ============================================================================

if __name__ == "__main__":
    # Example usage
    print("Configuration Examples:")
    print("=" * 50)

    # Create config for mBERT
    config = ProjectConfig(model_type="mbert")
    print(f"Model: {config.model.MODEL_NAME}")
    print(f"Batch Size: {config.model.BATCH_SIZE}")
    print(f"Learning Rate: {config.model.LEARNING_RATE}")

    # Get preset configuration
    fast_config = get_preset_config("fast", model_type="xlmr")
    print(f"\nFast Training Config:")
    print(f"Epochs: {fast_config.model.NUM_EPOCHS}")
    print(f"Sequence Length: {fast_config.data.MAX_SEQUENCE_LENGTH}")

    # Save configuration
    config.save_config("example_config.json")
    print("\nConfiguration saved to example_config.json")